{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fancyimpute import IterativeSVD\n",
    "from fancyimpute import KNN\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Path management"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base: str\n",
    "if os.getcwd() == \"/kaggle/working\":\n",
    "    base = \"/kaggle\"\n",
    "else:\n",
    "    base = os.path.join(os.getcwd())\n",
    "\n",
    "def get_full_dir(sub_dir: str) -> str:\n",
    "    return os.path.join(base, sub_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sample_submission: pd.DataFrame = pd.read_csv(get_full_dir('input/playground-series-s3e15/sample_submission.csv'))\n",
    "df_data: pd.DataFrame = pd.read_csv(get_full_dir('input/playground-series-s3e15/data.csv'), index_col='id')\n",
    "df_og: pd.DataFrame = pd.read_csv(get_full_dir('input/predicting-heat-flux/Data_CHF_Zhao_2020_ATE.csv'), index_col='id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_data.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_og.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Our training data contains lots of missing values, we could impute them using a very simple strategy like mean or median however this will likely result is poor model quality due to the about of missing value. Instead, we can also predict what value the missing value should have based off the other non-null value in these columns. The original data could be very he puff for that purpose since it does not contain any missing values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_sample_submission.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### As describe in the completions we are prediction the missing values for x_e_out, our test data consist of all the row with missing x_e_out."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_og.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=len(df_data.columns), ncols=4, figsize=(26, 50))\n",
    "axes = axes.flatten()\n",
    "\n",
    "def graph_numerical_feature(data: list[tuple[pd.DataFrame, str, str]], target: str, axes_start_i: int) -> None:\n",
    "    # Plot densities\n",
    "    for df, column, label in data:\n",
    "        sns.kdeplot(df[column], label=label, ax=axes[axes_start_i], fill=False)\n",
    "    for df, column, label in data:\n",
    "        sns.histplot(df[column], label=label, ax=axes[axes_start_i + 1], stat=\"density\", bins=50)\n",
    "\n",
    "    # Plot boxplot\n",
    "    tmp_data_dict = {}\n",
    "    for df, column, label in data:\n",
    "        tmp_data_dict[label] = df[column]\n",
    "    df_tmp = pd.DataFrame(tmp_data_dict)\n",
    "    sns.boxplot(data=df_tmp, ax=axes[axes_start_i + 2])\n",
    "    axes[axes_start_i + 2].set_xlabel(col)\n",
    "\n",
    "    # Plot target correlation\n",
    "    for df, column, label in data:\n",
    "        sns.scatterplot(x=column, y=target, label=label, ax=axes[axes_start_i + 3], data=df)\n",
    "\n",
    "    # Plot legends\n",
    "    axes[axes_start_i].legend()\n",
    "    axes[axes_start_i + 1].legend()\n",
    "    axes[axes_start_i + 3].legend()\n",
    "\n",
    "def graph_categorical_feature(data: list[tuple[pd.DataFrame, str, str]], target: str, axes_start_i: int) -> None:\n",
    "    # Makes sure that the categories are shown in the same order\n",
    "    category_order: list[str] = data[0][0][data[0][1]].unique()\n",
    "\n",
    "    # Plot barplots\n",
    "    for il, data_pack in enumerate(data):\n",
    "        df, column, label = data_pack\n",
    "        sns.countplot(x=column, data=df, label=label, order=category_order, ax=axes[axes_start_i + il])\n",
    "        axes[axes_start_i + il].tick_params(axis='x', rotation=90)  # Rotate x-axis labels\n",
    "\n",
    "    # Plot target correlation\n",
    "    for il, data_pack in enumerate(data):\n",
    "        df, column, label = data_pack\n",
    "        sns.barplot(x=column, y=target, data=df, label=label, order=category_order, ax=axes[axes_start_i + 2 + il])\n",
    "        axes[axes_start_i + 2 + il].tick_params(axis='x', rotation=90)  # Rotate x-axis labels\n",
    "\n",
    "    # Plot legends\n",
    "    axes[axes_start_i].legend()\n",
    "    axes[axes_start_i + 1].legend()\n",
    "    axes[axes_start_i + 2].legend()\n",
    "    axes[axes_start_i + 3].legend()\n",
    "\n",
    "\n",
    "i = 0\n",
    "for col in df_data.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df_data[col]):\n",
    "        graph_numerical_feature([(df_data, col, 'given'), (df_og, col, 'original')], 'x_e_out [-]', i)\n",
    "    else:\n",
    "        graph_categorical_feature([(df_data, col, 'given'), (df_og, col, 'original')], 'x_e_out [-]', i)\n",
    "    i += 4\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### The original data closely follows the distribution of our given synthetic data. This suggesting the value where nulled in our given data set evenly across all features, this means that original data should be good to use without introduction feature or distribution bias."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_feature_correlation(df: pd.DataFrame, title: str):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    corr_matrix = df.select_dtypes(include='number').corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr_matrix, dtype=bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, mask=mask)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "show_feature_correlation(df_data, \"Given\")\n",
    "show_feature_correlation(df_og, \"Original\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Prep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "categorical_columns = ['author', 'geometry']\n",
    "label_encoders = {}\n",
    "\n",
    "def label_encode(df: pd.DataFrame) -> None:\n",
    "    for column in categorical_columns:\n",
    "        label_encoder: LabelEncoder = LabelEncoder()\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "        label_encoders[column] = label_encoder\n",
    "\n",
    "def reverse_encode(df: pd.DataFrame) -> None:\n",
    "    for column in label_encoders.keys():\n",
    "        df[column] = df[column].astype(int)\n",
    "        df[column] = label_encoders[column].inverse_transform(df[column])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train: pd.DataFrame = pd.concat([df_data, df_og])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_encode(df_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline 0: Impute all missing numerical value including target using MICE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numerical_columns = ['pressure [MPa]', 'mass_flux [kg/m2-s]', 'x_e_out [-]', 'D_e [mm]', 'D_h [mm]', 'length [mm]']\n",
    "target = 'x_e_out [-]'\n",
    "\n",
    "# Create an instance of imputer\n",
    "imputer = IterativeSVD()\n",
    "#imputer = KNN()\n",
    "\n",
    "# Perform the imputation\n",
    "df_train_imputed = pd.DataFrame(imputer.fit_transform(df_train), columns=df_train.columns)\n",
    "# Print the imputed DataFrame\n",
    "print(\"Imputed DataFrame:\")\n",
    "df_train_imputed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train_imputed.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_predictions = df_train_imputed.iloc[df_sample_submission['id']]\n",
    "df_predictions = df_predictions['x_e_out [-]']\n",
    "df_predictions.to_csv('submission.csv', index_label=\"id\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
